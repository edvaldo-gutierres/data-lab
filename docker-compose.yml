version: '3'
services:
  minio:
    image: minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - ./data:/data
    networks:
      - datalake-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  spark:
    image: my-spark
    ports:
      - "8888:8888"
      - "4040:4040"
    volumes:
      - ./notebooks:/notebooks
    depends_on:
      - minio
    networks:
      - datalake-network

  dremio:
    image: dremio/dremio-oss
    ports:
      - "9047:9047"
    depends_on:
      - minio
      - hive-metastore
    networks:
      - datalake-network

  mariadb:
    image: mariadb:10.5
    environment:
      MYSQL_ROOT_PASSWORD: admin
      MYSQL_USER: hive
      MYSQL_PASSWORD: hive
      MYSQL_DATABASE: metastore_db
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p$$MYSQL_ROOT_PASSWORD"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - datalake-network

  hive-metastore:
    build:
      context: ./hive
      dockerfile: Dockerfile
    environment:
      MYSQL_HOST: mariadb
      MYSQL_PORT: 3306
      MYSQL_USER: hive
      MYSQL_PASSWORD: hive
      MYSQL_DATABASE: metastore_db
      SKIP_SCHEMA_INIT: "false"
    volumes:
      - ./hive/logs:/opt/hive/logs
      - ./hive/warehouse:/opt/hive/warehouse
    ports:
      - "9083:9083"
    depends_on:
      mariadb:
        condition: service_healthy
    networks:
      - datalake-network

  # Início dos novos serviços

  # Airflow
  airflow-postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow-postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    networks:
      - datalake-network

  airflow-webserver:
    image: apache/airflow:2.6.1
    depends_on:
      - airflow-postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - _AIRFLOW_DB_UPGRADE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=airflow
      - _AIRFLOW_WWW_USER_PASSWORD=airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    networks:
      - datalake-network

  airflow-scheduler:
    image: apache/airflow:2.6.1
    depends_on:
      - airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
    command: scheduler
    networks:
      - datalake-network

  # OpenMetadata
  openmetadata-mysql:
    image: mysql:8
    restart: always
    environment:
      - MYSQL_ROOT_PASSWORD=openmetadata_password
      - MYSQL_USER=openmetadata_user
      - MYSQL_PASSWORD=openmetadata_password
      - MYSQL_DATABASE=openmetadata_db
    volumes:
      - openmetadata-mysql-data:/var/lib/mysql
    networks:
      - datalake-network
    healthcheck:
      test: mysqladmin ping -h localhost -u $$MYSQL_USER --password=$$MYSQL_PASSWORD
      interval: 10s
      timeout: 10s
      retries: 5

  openmetadata:
    image: openmetadata/server:0.12.3
    depends_on:
      - openmetadata-mysql
    environment:
      # Database configuration
      - OPENMETADATA_CATALOG_DATABASE_USER=openmetadata_user
      - OPENMETADATA_CATALOG_DATABASE_PASSWORD=openmetadata_password
      - OPENMETADATA_CATALOG_DATABASE_HOST=openmetadata-mysql
      - OPENMETADATA_CATALOG_DATABASE_PORT=3306
      # Airflow configuration
      - AIRFLOW_HOST=http://airflow-webserver:8080
      # Adicionar essa variável para corrigir o problema de conexão
      - DB_HOST=openmetadata-mysql
    ports:
      - "8585:8585"
    networks:
      - datalake-network

  # Metabase - Ferramenta de Visualização
  metabase-db:
    image: postgres:13
    environment:
      POSTGRES_USER: metabase
      POSTGRES_PASSWORD: metabase
      POSTGRES_DB: metabase
    volumes:
      - metabase-db-data:/var/lib/postgresql/data
    networks:
      - datalake-network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "metabase"]
      interval: 5s
      retries: 5

  metabase:
    image: metabase/metabase:latest
    ports:
      - "3000:3000"
    environment:
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: metabase
      MB_DB_PORT: 5432
      MB_DB_USER: metabase
      MB_DB_PASS: metabase
      MB_DB_HOST: metabase-db
      JAVA_TIMEZONE: America/Sao_Paulo
    depends_on:
      - metabase-db
      - minio
    networks:
      - datalake-network
    restart: always

networks:
  datalake-network:
    external: false

volumes:
  airflow-postgres-db-volume:
  openmetadata-mysql-data:
  metabase-db-data: 